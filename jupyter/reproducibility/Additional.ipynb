{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Results\n",
    "\n",
    "This notebook is for generating plots that require different models. It will not be detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "os.chdir(\"../..\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "\n",
    "N_THREADS = 8\n",
    "IS_FORCE_CPU = False  # Nota Bene : notebooks don't deallocate GPU memory\n",
    "\n",
    "if IS_FORCE_CPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "torch.set_num_threads(N_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from npf.utils.datasplit import (\n",
    "    CntxtTrgtGetter,\n",
    "    GetRandomIndcs,\n",
    "    GridCntxtTrgtGetter,\n",
    "    RandomMasker,\n",
    "    get_all_indcs,\n",
    "    no_masker,\n",
    ")\n",
    "from utils.data import cntxt_trgt_collate, get_test_upscale_factor\n",
    "from utils.ntbks_helpers import get_all_gp_datasets, get_img_datasets\n",
    "\n",
    "# DATASETS\n",
    "# merges : get_datasets_single_gp, get_datasets_varying_hyp_gp, get_datasets_varying_kernel_gp\n",
    "gp_datasets, gp_test_datasets, gp_valid_datasets = get_all_gp_datasets()\n",
    "\n",
    "\n",
    "# CONTEXT TARGET SPLIT\n",
    "get_cntxt_trgt_1d = cntxt_trgt_collate(\n",
    "    CntxtTrgtGetter(\n",
    "        contexts_getter=GetRandomIndcs(a=0.0, b=50), targets_getter=get_all_indcs,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from npf import CNP, AttnCNP\n",
    "from npf.architectures import MLP, merge_flat_input\n",
    "from utils.helpers import count_parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R_DIM = 128\n",
    "KWARGS = dict(\n",
    "    XEncoder=partial(MLP, n_hidden_layers=1, hidden_size=R_DIM),\n",
    "    r_dim=R_DIM,\n",
    "    x_dim=1,\n",
    "    y_dim=1,\n",
    ")\n",
    "\n",
    "\n",
    "model_1d = dict()\n",
    "\n",
    "# 1D case\n",
    "model_1d[\"CNP\"] = partial(\n",
    "    CNP,\n",
    "    XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "        partial(MLP, n_hidden_layers=2, hidden_size=R_DIM * 2), is_sum_merge=True,\n",
    "    ),\n",
    "    **KWARGS,\n",
    ")\n",
    "\n",
    "\n",
    "# 1D case\n",
    "model_1d[\"AttnCNP\"] = partial(\n",
    "    AttnCNP,\n",
    "    attention=\"transformer\",  # multi headed attention with normalization and skip connections\n",
    "    is_self_attn=False,\n",
    "    XYEncoder=merge_flat_input(  # MLP takes single input but we give x and y so merge them\n",
    "        partial(MLP, n_hidden_layers=2, hidden_size=R_DIM), is_sum_merge=True,\n",
    "    ),\n",
    "    **KWARGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading RBF_Kernel/CNP/run_0 ---\n",
      "\n",
      "RBF_Kernel/CNP/run_0 | best epoch: None | train loss: 8.4633 | valid loss: None | test log likelihood: -16.1129\n",
      "\n",
      "--- Loading RBF_Kernel/AttnCNP/run_0 ---\n",
      "\n",
      "RBF_Kernel/AttnCNP/run_0 | best epoch: None | train loss: -157.9417 | valid loss: None | test log likelihood: 149.158\n",
      "\n",
      "--- Loading Periodic_Kernel/CNP/run_0 ---\n",
      "\n",
      "Periodic_Kernel/CNP/run_0 | best epoch: None | train loss: 129.0426 | valid loss: None | test log likelihood: -126.4177\n",
      "\n",
      "--- Loading Periodic_Kernel/AttnCNP/run_0 ---\n",
      "\n",
      "Periodic_Kernel/AttnCNP/run_0 | best epoch: None | train loss: 21.2395 | valid loss: None | test log likelihood: -25.4617\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/CNP/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/CNP/run_0 | best epoch: None | train loss: 111.3382 | valid loss: None | test log likelihood: -115.7692\n",
      "\n",
      "--- Loading Noisy_Matern_Kernel/AttnCNP/run_0 ---\n",
      "\n",
      "Noisy_Matern_Kernel/AttnCNP/run_0 | best epoch: None | train loss: 87.5571 | valid loss: None | test log likelihood: -91.5147\n",
      "\n",
      "--- Loading Variable_Matern_Kernel/CNP/run_0 ---\n",
      "\n",
      "Variable_Matern_Kernel/CNP/run_0 | best epoch: None | train loss: -91.6702 | valid loss: None | test log likelihood: -1076.2766\n",
      "\n",
      "--- Loading Variable_Matern_Kernel/AttnCNP/run_0 ---\n",
      "\n",
      "Variable_Matern_Kernel/AttnCNP/run_0 | best epoch: None | train loss: -204.3232 | valid loss: None | test log likelihood: -4009.3233\n",
      "\n",
      "--- Loading All_Kernels/CNP/run_0 ---\n",
      "\n",
      "All_Kernels/CNP/run_0 | best epoch: None | train loss: 79.7617 | valid loss: None | test log likelihood: -80.6751\n",
      "\n",
      "--- Loading All_Kernels/AttnCNP/run_0 ---\n",
      "\n",
      "All_Kernels/AttnCNP/run_0 | best epoch: None | train loss: 74.5616 | valid loss: None | test log likelihood: -116.8501\n"
     ]
    }
   ],
   "source": [
    "import skorch\n",
    "from npf import CNPFLoss\n",
    "from utils.ntbks_helpers import add_y_dim\n",
    "from utils.train import train_models\n",
    "\n",
    "KWARGS = dict(\n",
    "    is_retrain=False,  # whether to load precomputed model or retrain\n",
    "    criterion=CNPFLoss,  # (approx) conditional ELBO Loss\n",
    "    chckpnt_dirname=\"results/pretrained/\",\n",
    "    device=None,  # use GPU if available\n",
    "    batch_size=32,\n",
    "    lr=1e-3,\n",
    "    decay_lr=10,  # decrease learning rate by 10 during training\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "\n",
    "# 1D\n",
    "trainers_1d = train_models(\n",
    "    gp_datasets,\n",
    "    model_1d,\n",
    "    test_datasets=gp_test_datasets,\n",
    "    iterator_train__collate_fn=get_cntxt_trgt_1d,\n",
    "    iterator_valid__collate_fn=get_cntxt_trgt_1d,\n",
    "    max_epochs=100,\n",
    "    **KWARGS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ntbks_helpers import PRETTY_RENAMER, plot_multi_posterior_samples_1d\n",
    "from utils.visualize import giffify\n",
    "\n",
    "\n",
    "def multi_posterior_gp_gif(filename, trainers, datasets, seed=123, **kwargs):\n",
    "    giffify(\n",
    "        save_filename=f\"jupyter/gifs/{filename}.gif\",\n",
    "        gen_single_fig=plot_multi_posterior_samples_1d,  # core plotting\n",
    "        sweep_parameter=\"n_cntxt\",  # param over which to sweep\n",
    "        sweep_values=[0, 2, 5, 7, 10, 15, 20, 30, 50, 100],\n",
    "        fps=1.2,  # gif speed\n",
    "        # PLOTTING KWARGS\n",
    "        trainers=trainers,\n",
    "        datasets=datasets,\n",
    "        is_plot_generator=True,  # plot underlying GP\n",
    "        is_plot_real=False,  # don't plot sampled / underlying function\n",
    "        is_plot_std=True,  # plot the predictive std\n",
    "        is_fill_generator_std=False,  # do not fill predictive of GP\n",
    "        pretty_renamer=PRETTY_RENAMER,  # pretiffy names of modulte + data\n",
    "        # Fix formatting for coherent GIF\n",
    "        plot_config_kwargs=dict(\n",
    "            set_kwargs=dict(ylim=[-3, 3]), rc={\"legend.loc\": \"upper right\"}\n",
    "        ),\n",
    "        seed=seed,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_rbf(d):\n",
    "    \"\"\"Select only data form RBF.\"\"\"\n",
    "    return {k: v for k, v in d.items() if (\"RBF\" in k)}\n",
    "\n",
    "multi_posterior_gp_gif(\n",
    "    \"CNP_AttnCNP_rbf_extrap\",\n",
    "    trainers=filter_rbf(trainers_1d),\n",
    "    datasets=filter_rbf(gp_test_datasets),\n",
    "    left_extrap=-2,  # shift signal 2 to the right for extrapolation\n",
    "    right_extrap=2,  # shift signal 2 to the right for extrapolation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "npf",
   "language": "python",
   "name": "npf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
