

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Conditional NPFs &#8212; Neural Process Family</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/proof.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Latent NPFs" href="LNPFs.html" />
    <link rel="prev" title="Neural Process Family" href="Intro.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="Intro.html">Neural Process Family</a>
  </li>
  <li class="active">
    <a href="">Conditional NPFs</a>
  </li>
  <li class="">
    <a href="LNPFs.html">Latent NPFs</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Advanced</p>
</li>
  <li class="">
    <a href="Theory.html">Theory</a>
  </li>
  <li class="">
    <a href="Training.html">Training</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Reproducibility</p>
</li>
  <li class="">
    <a href="../reproducibility/Datasets.html">Datasets</a>
  </li>
  <li class="">
    <a href="../reproducibility/CNP.html">CNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/AttnCNP.html">AttnCNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/ConvCNP.html">ConvCNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/LNP.html">LNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/AttnLNP.html">AttnLNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/ConvLNP.html">ConvLNP</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Reference</p>
</li>
  <li class="">
    <a href="Related.html">Related</a>
  </li>
  <li class="">
    <a href="../zbibliography.html">Bibliography</a>
  </li>
  <li class="">
    <a href="https://github.com/YannDubs/Neural-Process-Family">GitHub Repo<i class="fas fa-external-link-alt"></i></a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/text/CNPFs.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/YannDubs/Neural-Process-Family"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#overview" class="nav-link">Overview</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#conditional-neural-process-cnp" class="nav-link">Conditional Neural Process (CNP)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#attentive-conditional-neural-process-attncnp" class="nav-link">Attentive Conditional Neural Process (AttnCNP)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#convolutional-conditional-neural-process-convcnp" class="nav-link">Convolutional Conditional Neural Process (ConvCNP)</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#issues-with-cnpfs" class="nav-link">Issues With CNPFs</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="conditional-npfs">
<h1>Conditional NPFs<a class="headerlink" href="#conditional-npfs" title="Permalink to this headline">¶</a></h1>
<div class="figure align-default" id="graph-model-cnpf">
<a class="reference internal image-reference" href="../_images/graph_model_CNPF.svg"><img alt="../_images/graph_model_CNPF.svg" src="../_images/graph_model_CNPF.svg" width="200em" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Graphical model for the Conditional NPFs.</span><a class="headerlink" href="#graph-model-cnpf" title="Permalink to this image">¶</a></p>
</div>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>We previously saw that the aim of NPFs is to model the posterior predictive <span class="math notranslate nohighlight">\(p( \mathbf{y}_\mathcal{T}' | \mathbf{y}_\mathcal{C}; \mathbf{x}_\mathcal{C}, \mathbf{x}_\mathcal{T})\)</span>, before diving into how we do so, let’s take a step back and think about <strong>why</strong> we want to do so.
The usecase we will first consider is when we want to arg maximize the posterior predictive <span class="math notranslate nohighlight">\(\mathbf{y}_\mathcal{T}^* = \arg \max_{\mathbf{y}_\mathcal{T}'} p( \mathbf{y}_\mathcal{T}' | \mathbf{y}_\mathcal{C}; \mathbf{x}_\mathcal{C}, \mathbf{x}_\mathcal{T})\)</span> in a computational efficient manner.
This can be used for imputing missing values or meta-learning […].
For example in GPs you would first have to infer the posterior predictive (computationally prohibitive) and then it is very simple to compute the arg maximum as the predictive is Gaussian so the mode is simply the mean of the Gaussian.</p>
<p>Conditional Neural Process Sub-Family (CNPFs) are model that enable efficiently finding <span class="math notranslate nohighlight">\(\mathbf{y}_\mathcal{T}^*\)</span> through forward pass of the network. The idea is to encode the entire context set in a fixed representation <span class="math notranslate nohighlight">\(R\)</span> and to have a simple distribution of the target set conditioned on <span class="math notranslate nohighlight">\(R\)</span>.
To decrease the computational complexity we will assume that the targets are independent conditioned on <span class="math notranslate nohighlight">\(R\)</span>.
What is more we will assume that they follow a Gaussian distribution, which enables efficient arg maximization by considering the predictive mean.
They all have the same probabilistic graphical model (<a class="reference internal" href="#graph-model-cnpf"><span class="std std-numref">Fig. 5</span></a>), specifically they model the posterior predictive as follows:</p>
<div class="math notranslate nohighlight" id="equation-formal">
<span class="eqno">(3)<a class="headerlink" href="#equation-formal" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
p(\mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, \mathcal{c}) 
&amp;\approx q_{\boldsymbol\theta}(\mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, \mathcal{C}) &amp; \text{Parametrization}\\
&amp;= q_{\boldsymbol\theta}(\mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, R) &amp; \text{Sufficiency}  \\
&amp;= \prod_{t=1}^{T} q_{\boldsymbol\theta}(y^{(t)} |  x^{(t)}, R)  &amp; \text{Factorization}\\
&amp;= \prod_{t=1}^{T} \mathcal{N}\left( y^{(t)};  \mu^{(t)},
\sigma^{2(t)}
\right) &amp; \text{Gaussian} 
\end{align}\end{split}\]</div>
<p>Where:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
R^{(c)} 
&amp;:= e_{\boldsymbol\theta}(x^{(c)}, y^{(c)}) &amp; \text{Encoding} \\
R 
&amp;:= \mathrm{Agg}\left(\{R^{(c)}\}_{c=1}^{C} \right) &amp; \text{Aggregation} \\ 
(\mu^{(t)},\sigma^{2(t)}) 
&amp;:= d_{\boldsymbol\theta}(x^{(t)},R) &amp; \text{Decoding}  
\end{align}
\end{split}\]</div>
<p>And the aggregator is permutation invariant (Eq. <a class="reference internal" href="Intro.html#equation-permut-inv">(1)</a>).</p>
<p>The training of CNPFs is straight forward and consists in optimizing a the likelihood (Eq. <a class="reference internal" href="Intro.html#equation-training">(2)</a>).</p>
</div>
<div class="section" id="conditional-neural-process-cnp">
<h2>Conditional Neural Process (CNP)<a class="headerlink" href="#conditional-neural-process-cnp" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="computational-graph-cnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_CNPs1.svg"><img alt="Computational graph CNP" src="../_images/computational_graph_CNPs1.svg" width="300em" /></a>
<p class="caption"><span class="caption-number">Fig. 6 </span><span class="caption-text">Computational graph for CNP.</span><a class="headerlink" href="#computational-graph-cnps-text" title="Permalink to this image">¶</a></p>
</div>
<p>Conditional Neural Process <a class="bibtex reference internal" href="../zbibliography.html#garnelo2018conditional" id="id1">[GRM+18]</a>:</p>
<ul class="simple">
<li><p>use mean for aggregation because it’s a simple permutation invariant function (sum is commutative) + say how relates to deep sets</p></li>
<li><p>computational cost <span class="math notranslate nohighlight">\(\mathcal{O}(T+C)\)</span> + computational graph <a class="reference internal" href="#computational-graph-cnps-text"><span class="std std-numref">Fig. 6</span></a></p></li>
</ul>
<p>Let’s see how it works on some data.
We first consider a simple 1D setting with samples from a GP with RBF kernel (data details in <a class="reference internal" href="../reproducibility/Datasets.html"><span class="doc">Datasets Notebook</span></a>):</p>
<div class="figure align-default" id="cnp-rbf-text">
<a class="reference internal image-reference" href="../_images/CNP_rbf.gif"><img alt="CNP on GP with RBF kernel" src="../_images/CNP_rbf.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 7 </span><span class="caption-text">Posterior predictive of CNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#cnp-rbf-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#cnp-rbf-text"><span class="std std-numref">Fig. 7</span></a> we see that CNP performs quite well in this setting.
That being said it somewhat underfitts as seen by the fact that it  doesn’t go through all the context points even though there is no noise.</p>
<div class="figure align-default" id="cnp-periodic-text">
<a class="reference internal image-reference" href="../_images/CNP_periodic.gif"><img alt="CNP on GP with Periodic kernel" src="../_images/CNP_periodic.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 8 </span><span class="caption-text">Posterior predictive of CNPs (Blue) and the oracle GP (Green) with Periodic kernel.</span><a class="headerlink" href="#cnp-periodic-text" title="Permalink to this image">¶</a></p>
</div>
<p>This underfitting becomes apparent when the kernel is more complex as seen when the CNP is trained on a periodic GP.</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details, training and many more plots in <a class="reference internal" href="../reproducibility/CNP.html"><span class="doc">CNP Notebook</span></a></p>
</div>
</div>
<div class="section" id="attentive-conditional-neural-process-attncnp">
<h2>Attentive Conditional Neural Process (AttnCNP)<a class="headerlink" href="#attentive-conditional-neural-process-attncnp" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="computational-graph-attncnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_AttnCNPs1.svg"><img alt="Computational graph of AttnCNP" src="../_images/computational_graph_AttnCNPs1.svg" width="300em" /></a>
<p class="caption"><span class="caption-number">Fig. 9 </span><span class="caption-text">Computational graph for AttnCNP.</span><a class="headerlink" href="#computational-graph-attncnps-text" title="Permalink to this image">¶</a></p>
</div>
<p>The major insight behind AttnCNP<a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id2">[KMS+19]</a><a class="footnote-reference brackets" href="#attncnp" id="id3">1</a> is that CNP underfitts because it uses a target independent representation, i.e. all the points in the context set have “the same importance” in the global representation.
They alleviate this problem by using a target specific representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span>  (<a class="reference internal" href="#computational-graph-attncnps-text"><span class="std std-numref">Fig. 9</span></a>).</p>
<div class="dropdown caution admonition">
<p class="admonition-title">Advanced</p>
<p>[…keep…] ?
An other perspective, which we will be useful later on, is that the representation of the context <span class="math notranslate nohighlight">\(R\)</span> is actually a function instead of a vector.
This function will be queried at the target position <span class="math notranslate nohighlight">\(x^{(t)}\)</span> to yield a target specific vector representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span>.</p>
</div>
<p>AttnCNP computes that representation using attention mechanism (<a class="bibtex reference internal" href="../zbibliography.html#bahdanau2014neural" id="id4">[BCB14]</a>), which intuitively queries the context points with a target point to get a target specific representation of the context set.
[… quick explanation of attention …]</p>
<div class="dropdown caution admonition">
<p class="admonition-title">Advanced</p>
<p>Why attention satisfies deep sets</p>
</div>
<p>To illustrate how this alleviates underfitting, imagine that you are querying a target point at the position of a context point, then you will mostly attent to that specific context point and will predict exactly assuming that there is no noise.
Note that this comes at the cost of additional computational complexity: from  <span class="math notranslate nohighlight">\(\mathcal{O}(T+C)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{O}(C(C*T))\)</span> although it can be efficiently parallelized on GPUs.</p>
<div class="dropdown important admonition">
<p class="admonition-title">Computational Complexity</p>
<p>For every target we now have to attend to a representaion at each context element (cross attention).
For each target point a representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span> is then computed using cross-attention <span class="math notranslate nohighlight">\(\mathcal{O}(C*T)\)</span>.
In addition, the context representations (target indepent) usually first go through a self attention layer, where each context point attends to one another <span class="math notranslate nohighlight">\(\mathcal{O}(C^2)\)</span>.
Putting all together that gives  <span class="math notranslate nohighlight">\(\mathcal{O}(C(C*T))\)</span> computational complexity.</p>
</div>
<p>Without further due, let us see how well it perform in practice. We will first evaluate it on GPs from different kernels (RBF, periodic, Noisy Matern).</p>
<div class="figure align-default" id="attncnp-single-gp-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_single_gp1.gif"><img alt="AttnCNP on GPs with RBF, periodic, noisy Matern kernel" src="../_images/AttnCNP_single_gp1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 10 </span><span class="caption-text">Posterior predictive of AttnCNPs (Blue) and the oracle GP (Green) with RBF,Periodic,noisy Matern kernel.</span><a class="headerlink" href="#attncnp-single-gp-text" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#attncnp-single-gp-text"><span class="std std-numref">Fig. 10</span></a> shows that AttnCNP does not really suffer from underfitting and perform much better than CNP on challenging kernels.
That being said it is still not perfect:</p>
<ul class="simple">
<li><p>Periodic kernel not great</p></li>
<li><p>Looking carefully at the Matern and RBF kernel, we also see that AttnCNP has a posterior predictive with “kinks”, i.e., it is not very smooth. Note that kinks usually appear in the middle of 2 context points, we believe that they are a consequence of AttnCNP the abruptly changing its attention from one context point to the other (due to the exponential in the softmax).</p></li>
</ul>
<p>Overall, AttnCNP performs quite well in this simple setting. Let us investigate more realistic setting, when we do not have access to the underlying data generating process : images.
Note that each image can indeed be seen as a 2D function mapping pixel location to values, so we can try to model the underlying stochastic process.
Just as in 1D we want to model the posterior distribution of target pixels (all the image) given a few context pixels.</p>
<div class="figure align-default" id="attncnp-img-interp-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_img_interp.gif"><img alt="AttnCNP on CelebA and MNIST" src="../_images/AttnCNP_img_interp.gif" style="width: 30em;" /></a>
<p class="caption"><span class="caption-number">Fig. 11 </span><span class="caption-text">Posterior predictive of an AttnCNP for CelebA <span class="math notranslate nohighlight">\(32\times32\)</span> and MNIST.</span><a class="headerlink" href="#attncnp-img-interp-text" title="Permalink to this image">¶</a></p>
</div>
<p>Again we see from  <a class="reference internal" href="#attncnp-img-interp-text"><span class="std std-numref">Fig. 11</span></a> that AttnCNP perform well.
This really shows an advantage of CNPs compared to other ways of modelling stochastic processes, i.e., it can model complicated underlying stochastic processes from data instead of having to select a kernel.
Intuitively it implicitely models a kernel using the data and through the architecture of the model.</p>
<p>One big problems with neural networks is that they are terrible at generalizing outside of the training distribution.
For example let us take an AttnCNP trained on MNIST (augmented with translations) and test it on a larger canvas with 2 digits (Zero Shot Multi MNIST, ZSMM).</p>
<div class="figure align-default" id="attncnp-img-extrap-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_img_extrap.gif"><img alt="AttnCNP on ZSMM" src="../_images/AttnCNP_img_extrap.gif" style="width: 15em;" /></a>
<p class="caption"><span class="caption-number">Fig. 12 </span><span class="caption-text">Posterior predictive of an AttnCNP for ZSMM.</span><a class="headerlink" href="#attncnp-img-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p>We see in <a class="reference internal" href="#attncnp-rbf-extrap-text"><span class="std std-numref">Fig. 13</span></a> that the model indeed completely breaks in this generalization task.
This is probably not surprising to anyone who worked with neural nets as the test set is significantly different of the training set, which is challenging.
But this issue arises in more subtle/benign.
For example, let us query the CNP on points outside of the training interval (extrapolation) in the simple case of modelling a GP with RBF kernel</p>
<div class="figure align-default" id="attncnp-rbf-extrap-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_rbf_extrap.gif"><img alt="extrapolation of AttnCNP on GPs with RBF kernel" src="../_images/AttnCNP_rbf_extrap.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 13 </span><span class="caption-text">Extrapolation (red dashes) of posterior predictive of AttnCNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#attncnp-rbf-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#attncnp-rbf-extrap-text"><span class="std std-numref">Fig. 13</span></a> clearly shows that AttnCNP breaks as soon as the target set is outside of the training regime, even tough the context points are also in the extrapolation regime.
In other words, the AttnCNP really was not able to model the the fact that RBF kernel is stationary, i.e., that the absolute position of target points is not important only their relative position compared to context points.</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details, training and many more plots in <a class="reference internal" href="../reproducibility/AttnCNP.html"><span class="doc">AttnCNP Notebook</span></a></p>
</div>
</div>
<div class="section" id="convolutional-conditional-neural-process-convcnp">
<h2>Convolutional Conditional Neural Process (ConvCNP)<a class="headerlink" href="#convolutional-conditional-neural-process-convcnp" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="computational-graph-convcnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_ConvCNPs1.svg"><img alt="Computational graph ConvCNP" height="300em" src="../_images/computational_graph_ConvCNPs1.svg" /></a>
<p class="caption"><span class="caption-number">Fig. 14 </span><span class="caption-text">Computational graph of ConvCNP [to keep ? to simplify ?].</span><a class="headerlink" href="#computational-graph-convcnps-text" title="Permalink to this image">¶</a></p>
</div>
<p>The idea<a class="footnote-reference brackets" href="#disclaimer" id="id5">2</a> behind ConvCNP <a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id6">[GBF+19]</a> , is to bake in stationarity in the CNP to enable generalization outside of the training regime and sample efficiency.
One of the most famous inductive bias baked in in neural nets is the idea of translation equivariance through convolutions [cite].
It turns out that stationarity is equivalent to translation equivariant and ConvCNP takes advantage of this by using an encoder which is both permutation invariant and translation equivariant.
It does so by using convolutions in the encoder, but instead of the usual convolutions it has to define convolutions in sets (to keep permutation invariance) […]
Functional representation […], discretization […], <a class="reference internal" href="#computational-graph-convcnps-text"><span class="std std-numref">Fig. 14</span></a> computational graph [to keep ? to simplify ?], Intuition of theorem 1 […]</p>
<div class="dropdown caution admonition">
<p class="admonition-title">Advanced</p>
<p>ConvDeepSet representation theorem […]
More information in <a class="reference internal" href="Theory.html"><span class="doc">Additional Theory</span></a></p>
</div>
<div class="dropdown important admonition">
<p class="admonition-title">Computational Complexity</p>
<p><span class="math notranslate nohighlight">\(\mathcal{O}(U(C*T))\)</span> […].</p>
</div>
<p>Now that the model is translation equivariant, we can test it in the more challenging extrapolation regime.</p>
<div class="figure align-default" id="convcnp-single-gp-extrap-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_single_gp_extrap1.gif"><img alt="../_images/ConvCNP_single_gp_extrap1.gif" src="../_images/ConvCNP_single_gp_extrap1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Extrapolation (red dashes) of posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with RBF,periodic,Matern kernel.</span><a class="headerlink" href="#convcnp-single-gp-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p><a class="reference internal" href="#convcnp-single-gp-extrap-text"><span class="std std-numref">Fig. 15</span></a> shows that ConvCNP performs very well:</p>
<ul class="simple">
<li><p>No underffiting</p></li>
<li><p>Can extrapolate outside of the training range due to its translation equivariance. Note that there is no free lunch, this only happens because the underlying stochastic process is stationary.</p></li>
<li><p>smooth  “no kinks”.</p></li>
<li><p>It perform well on the periodic kernel.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The periodic kernel example is a little misleading, indeed the ConvCNP does not recover the underlying GP.
Specifically, it cannot because it has a bounded receptive field and as a result can only model local periodicity as illusrated when considering a much larger target interval (<span class="math notranslate nohighlight">\([-2,14]\)</span> instead of <span class="math notranslate nohighlight">\([0,4]\)</span>). [… to keep …?]</p>
<div class="figure align-default" id="convcnp-periodic-large-extrap-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_periodic_large_extrap1.gif"><img alt="ConvCNP on single images" src="../_images/ConvCNP_periodic_large_extrap1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">Large extrapolation (red dashes) of posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with periodic kernel.</span><a class="headerlink" href="#convcnp-periodic-large-extrap-text" title="Permalink to this image">¶</a></p>
</div>
</div>
<p>Let us see whether it also performs well in the more challenging case of images.</p>
<div class="figure align-default" id="convcnp-img-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_img1.gif"><img alt="ConvCNP on CelebA, MNIST, ZSMM" src="../_images/ConvCNP_img1.gif" style="width: 45em;" /></a>
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text">Posterior predictive of an AttnCNP for CelebA, MNIST, and ZSMM.</span><a class="headerlink" href="#convcnp-img-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#convcnp-img-text"><span class="std std-numref">Fig. 17</span></a> we see that ConvCNP performs quite well on all datasets when the context set is large enough and uniformly sampled, even when extrapolation is needed (ZSMM).
However, it does not perform great when the context set is very small or when it is structured, e.g., half images. Note that seems more of an issue for ConvCNP compared to AttnCNP (<a class="reference internal" href="../reproducibility/AttnCNP.html#attncnp-img"><span class="std std-numref">Fig. 41</span></a>). We hypothesize that this happens because the effective receptive field of the former is too small.
This issue can be alleviated by reducing the size of the context set seen during training (to force the model to have a large receptive field).</p>
<p>Although the zero shot generalization when performing on ZSMM are encouraging, it still is a simple artificial dataset.
Let us consider a more complex zero shot generalization, namely we will evaluate the large model trained on CelebA128 on a image with multiple faces of different scale and orientation.</p>
<div class="figure align-default" id="convcnp-img-zeroshot-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_img_zeroshot.png"><img alt="Zero shot generalization of ConvCNP to a real picture" src="../_images/ConvCNP_img_zeroshot.png" style="width: 50em;" /></a>
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">Zero shot generalization of a ConvCNP trained on CelebA and evaluated on Ellen’s selfie</span><a class="headerlink" href="#convcnp-img-zeroshot-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#convcnp-img-zeroshot-text"><span class="std std-numref">Fig. 18</span></a> we see that the model is able to reasonably well generalize to real world data in a zero shot fashion.</p>
<p>Although the previous results look nice the usecases are not obvious as it is not very common to have missing pixels.
One possible application, is increasing the resolution of an image by querying positions “in between” pixels [… same figure as in intro, should we just link/referenve to it instead ? ]:</p>
<div class="figure align-default" id="convcnp-superes-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_superes.png"><img alt="Increasing image resolution with ConvCNP" src="../_images/ConvCNP_superes.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 19 </span><span class="caption-text">Increasing the resolution of <span class="math notranslate nohighlight">\(16 \times 16\)</span> CelebA to <span class="math notranslate nohighlight">\(128 \times 128\)</span> with a ConvCNP.</span><a class="headerlink" href="#convcnp-superes-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#convcnp-superes-text"><span class="std std-numref">Fig. 19</span></a> we see that NPFs can indeed be used to increase the resolution of an image, even though it was not trained to do so! Results can probably be improved by training NPFs in such setting.</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details, training and many more plots in <a class="reference internal" href="../reproducibility/ConvCNP.html"><span class="doc">ConvCNP Notebook</span></a></p>
</div>
<div class="section" id="issues-with-cnpfs">
<span id="issues-cnpfs"></span><h3>Issues With CNPFs<a class="headerlink" href="#issues-with-cnpfs" title="Permalink to this headline">¶</a></h3>
<p>Although the results look quite good there are still some issues with CNPFs.
The first issue is that it due to the factorized form of the predictive distribution (Eq. <a class="reference internal" href="#equation-formal">(3)</a>), CNPFs cannot be used to sample coherent functions from the posterior predictive as it assumes that all the target distributions are independent given the context set.
Sampling from the posterior correponds to adding independent noise to the mean at each target location:</p>
<div class="figure align-default" id="convcnp-rbf-samples-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_rbf_samples.png"><img alt="Sampling from ConvCNP on GP with RBF kernel" src="../_images/ConvCNP_rbf_samples.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-number">Fig. 20 </span><span class="caption-text">Samples form the posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#convcnp-rbf-samples-text" title="Permalink to this image">¶</a></p>
</div>
<p>An other issue of CNPFs is that they cannot model complex multi modal posterior distribution, as the posterior distribution at every target point is always a Gaussian [….]</p>
<div class="figure align-default" id="convcnp-marginal-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_marginal.png"><img alt="Samples from ConvCNP on MNIST and posterior of different pixels" src="../_images/ConvCNP_marginal.png" style="width: 20em;" /></a>
<p class="caption"><span class="caption-number">Fig. 21 </span><span class="caption-text">Samples form the posterior predictive of ConvCNPs on MNIST (left) and posterior predictive of some pixels (right).</span><a class="headerlink" href="#convcnp-marginal-text" title="Permalink to this image">¶</a></p>
</div>
<p>We will see how to solve both these issues by treating the representation as a latent variable in LNPFs.</p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="attncnp"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id7">[KMS+19]</a> only introduced the latent variable model, but one can easily drop the latent variable if not needed.</p>
</dd>
<dt class="label" id="disclaimer"><span class="brackets"><a class="fn-backref" href="#id5">2</a></span></dt>
<dd><p>Disclaimer : 2 co-authors</p>
</dd>
</dl>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Intro.html" title="previous page">Neural Process Family</a>
    <a class='right-next' id="next-link" href="LNPFs.html" title="next page">Latent NPFs</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois and Jonathan Gordon<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>