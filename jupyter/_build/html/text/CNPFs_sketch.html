

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Conditional NPFs &#8212; Neural Process Family</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.gif" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="Intro.html">Neural Process Family</a>
  </li>
  <li class="">
    <a href="CNPFs.html">Conditional NPFs</a>
  </li>
  <li class="">
    <a href="LNPFs.html">Latent NPFs</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Advanced</p>
</li>
  <li class="">
    <a href="Theory.html">Theory</a>
  </li>
  <li class="">
    <a href="Training.html">Training</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Reproducibility</p>
</li>
  <li class="">
    <a href="../reproducibility/Datasets.html">Datasets</a>
  </li>
  <li class="">
    <a href="../reproducibility/CNP.html">CNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/AttnCNP.html">AttnCNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/ConvCNP.html">ConvCNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/LNP.html">LNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/AttnLNP.html">AttnLNP</a>
  </li>
  <li class="">
    <a href="../reproducibility/ConvLNP.html">ConvLNP</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Reference</p>
</li>
  <li class="">
    <a href="Related.html">Related</a>
  </li>
  <li class="">
    <a href="../zbibliography.html">Bibliography</a>
  </li>
  <li class="">
    <a href="https://github.com/YannDubs/Neural-Process-Family">GitHub Repo<i class="fas fa-external-link-alt"></i></a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/text/CNPFs_sketch.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/YannDubs/Neural-Process-Family"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#overview" class="nav-link">Overview</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#conditional-neural-process-cnp" class="nav-link">Conditional Neural Process (CNP)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#attentive-conditional-neural-process-attncnp" class="nav-link">Attentive Conditional Neural Process (AttnCNP)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#generalisation-and-extrapolation" class="nav-link">Generalisation and Extrapolation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#convolutional-conditional-neural-process-convcnp" class="nav-link">Convolutional Conditional Neural Process (ConvCNP)</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#issues-with-cnpfs" class="nav-link">Issues With CNPFs</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="conditional-npfs">
<h1>Conditional NPFs<a class="headerlink" href="#conditional-npfs" title="Permalink to this headline">¶</a></h1>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<div class="figure align-default" id="graph-model-cnpf">
<a class="reference internal image-reference" href="../_images/graph_model_CNPF.svg"><img alt="../_images/graph_model_CNPF.svg" src="../_images/graph_model_CNPF.svg" width="200em" /></a>
<p class="caption"><span class="caption-text">Graphical model for the Conditional NPFs.</span><a class="headerlink" href="#graph-model-cnpf" title="Permalink to this image">¶</a></p>
</div>
<p>As we have seen, the key design choice of members of the NPF is how to model the predictive distribution <span class="math notranslate nohighlight">\(p( \mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{C}, \mathbf{x}_\mathcal{T})\)</span>.
One simplifying assumption that we could make, illustrated in <code class="xref std std-numref docutils literal notranslate"><span class="pre">graph_model_CNPF</span></code>, is that the predictive distribution <em>factorises</em> conditioned on the context set.
This means that, having observed the context set <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>, the prediction for each target location is <em>independent</em> of any other target locations.
We can concisely express this assumption as</p>
<div class="math notranslate nohighlight" id="equation-conditional-predictives">
<span class="eqno">()<a class="headerlink" href="#equation-conditional-predictives" title="Permalink to this equation">¶</a></span>\[\begin{align}
p( \mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, \mathcal{C}) = \prod_{t=1}^{T} p \left( y^{(t)} | x^{(t)}, \mathcal{C} \right).
\end{align}\]</div>
<p>A typical (though not <em>necessary</em>) choice is to consider Gaussian distributions for these likelihoods.
We collectively refer to members of the NPF that employ the factorisation assumption as <em>conditional</em> NP models, and to this sub-family as the CNPF.
Now, recall that one guiding principle of the NPF is to <em>locally</em> encode each input-output pair in <span class="math notranslate nohighlight">\(\mathcal{C}\)</span>, and then <em>aggregate</em> the encodings into a single representation of the context set, which we denote <span class="math notranslate nohighlight">\(R\)</span>.
Putting these together, we can express the predictive distribution of CNPF members as</p>
<div class="math notranslate nohighlight" id="equation-formal">
<span class="eqno">()<a class="headerlink" href="#equation-formal" title="Permalink to this equation">¶</a></span>\[\begin{split}\begin{align}
p_{\boldsymbol\theta}(\mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, \mathcal{C})
&amp;= p_{\boldsymbol\theta}(\mathbf{y}_\mathcal{T} | \mathbf{x}_\mathcal{T}, R) &amp; \text{Parameterisation}  \\
&amp;= \prod_{t=1}^{T} p_{\boldsymbol\theta}(y^{(t)} |  x^{(t)}, R)  &amp; \text{Factorisation}\\
&amp;= \prod_{t=1}^{T} \mathcal{N} \left( y^{(t)};  \mu^{(t)}, \sigma^{2(t)} \right) &amp; \text{Gaussian}
\end{align}\end{split}\]</div>
<p>Where:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
R^{(c)}
&amp;:= e_{\boldsymbol\theta} \left(x^{(c)}, y^{(c)} \right) &amp; \text{Encoding} \\
R
&amp;:= \mathrm{Agg}\left(\{R^{(c)}\}_{c=1}^{C} \right) &amp; \text{Aggregation} \\
(\mu^{(t)},\sigma^{2(t)})
&amp;:= d_{\boldsymbol\theta}(x^{(t)},R) &amp; \text{Decoding}  
\end{align}
\end{split}\]</div>
<p>CNPF members make an important tradeoff.
On one hand, we have placed a severe restriction on the class of models that we can fit, and this restriction has important consequences.
We discuss these consequences in further detail, as well as provide some illustrations, at the end of this chapter.
On the other hand, the factorisation assumption makes evaluation of the predictive likelihoods tractable.
This means that we can employ simple and exact maximum-likelihood procedures to train the model parameters.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Advanced</p>
<p>In the <a class="reference internal" href="Theory.html"><span class="doc">Theory</span></a> chapter we discuss the implications of an unbiased training procedure, and formalise what such a training procedure converges to.</p>
</div>
<p>Members of CNPF are distinguished by how they parameterise each of the key components:</p>
<ul class="simple">
<li><p>the encoding function <span class="math notranslate nohighlight">\(e_{\boldsymbol\theta}\)</span>,</p></li>
<li><p>the aggregation function <span class="math notranslate nohighlight">\(\mathrm{Agg}\)</span>, and</p></li>
<li><p>the decoder <span class="math notranslate nohighlight">\(d_{\boldsymbol\theta}\)</span>.</p></li>
</ul>
<p>Next, we detail some prominent members of the CNPF, and discuss some of their advantages and disadvantages.</p>
</div>
<div class="section" id="conditional-neural-process-cnp">
<h2>Conditional Neural Process (CNP)<a class="headerlink" href="#conditional-neural-process-cnp" title="Permalink to this headline">¶</a></h2>
<p>Arguably the simplest member of the CNPF, and the first considered in the literature, is the Conditional Neural Process (CNP) <a class="bibtex reference internal" href="../zbibliography.html#garnelo2018conditional" id="id1">[GRM+18]</a>.
The CNP is defined by the following design choices:</p>
<ul class="simple">
<li><p>The encoding function is defined by a feedforward MLP that takes as input the concatenation of <span class="math notranslate nohighlight">\(x^{(c)}\)</span> and <span class="math notranslate nohighlight">\(y^{(c)}\)</span>, and outputs a simple vector <span class="math notranslate nohighlight">\(R^{(c)} \in \mathbb{R}^{dr}\)</span>.</p></li>
<li><p>The aggregation function is a simple average over the representations <span class="math notranslate nohighlight">\(\frac{1}{| \mathcal{C} |} \sum_{c=1}^{| \mathcal{C} |} R^{(c)}\)</span>.</p></li>
<li><p>The decoder <span class="math notranslate nohighlight">\(d_{\boldsymbol\theta}\)</span> is also defined by a feedforward MLP that takes in the concatenation of <span class="math notranslate nohighlight">\(R\)</span> and <span class="math notranslate nohighlight">\(x^{(t)}\)</span>, and outputs a mean <span class="math notranslate nohighlight">\(\mu^{(t)}\)</span> and standard deviation <span class="math notranslate nohighlight">\(\sigma^{(t)}\)</span>.</p></li>
</ul>
<div class="dropdown tip admonition">
<p class="admonition-title">Note</p>
<p>You should convince yourself (if it is not immediately obvious) that averaging is indeed permutation invariant. Hint: the summation operation is commutative, and this is followed by simple division by <span class="math notranslate nohighlight">\(| \mathcal{C} |\)</span> to achieve “averaging”.</p>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">Details</p>
<p>There is a strong relationship between this form and DeepSets networks, introduced by <a class="bibtex reference internal" href="../zbibliography.html#zaheer2017deep" id="id2">[ZKR+17]</a>.
In the <a class="reference internal" href="Theory.html"><span class="doc">Theory</span></a> chapter we leverage this relationship to prove that CNPs can recover maps to any (continuous) mean and variance functions.</p>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Implementation Detail</p>
<p>Typically, we parameterise <span class="math notranslate nohighlight">\(d_{\boldsymbol\theta}\)</span> as outputting <span class="math notranslate nohighlight">\((\mu^{(t)}, \log \sigma^{(t)})\)</span>, i.e., the <em>log</em> standard deviation, so as to ensure that no negative variances occur.</p>
</div>
<p>The resulting computational graph is illustrated in <code class="xref std std-numref docutils literal notranslate"><span class="pre">computational_graph_CNPs_text</span></code>. It is easy to see that the computational cost of making predictions for <span class="math notranslate nohighlight">\(T\)</span> target set points conditioned on <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> with this design is <span class="math notranslate nohighlight">\(\mathcal{O}(T+|\mathcal{C}|)\)</span>.</p>
<div class="figure align-default" id="computational-graph-cnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_CNPs1.svg"><img alt="Computational graph CNP" src="../_images/computational_graph_CNPs1.svg" width="300em" /></a>
<p class="caption"><span class="caption-text">Computational graph for CNP.</span><a class="headerlink" href="#computational-graph-cnps-text" title="Permalink to this image">¶</a></p>
</div>
<p>Let’s see what prediction with such a model looks like in practice.
We first consider a simple 1D setting with samples from a GP with a radial basis function (RBF) kernel (data details in <a class="reference internal" href="../reproducibility/Datasets.html"><span class="doc">Datasets Notebook</span></a>).
Throughout the tutorial, we refer to similar experiments (though we vary the kernel) quite often.
Besides providing useful (and aesthetically pleasing) visualisations, the GPs admit ground truth predictive distributions, which allow us to compare to the “best possible” distributions for a given context set.</p>
<div class="figure align-default" id="cnp-rbf-text">
<a class="reference internal image-reference" href="../_images/CNP_rbf.gif"><img alt="CNP on GP with RBF kernel" src="../_images/CNP_rbf.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of CNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#cnp-rbf-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">CNP_rbf_text</span></code> provides the predictive distribution for a CNP trained on many samples from such a GP.
The blue line represents the predicted mean function, and the shaded region represents two standard deviations on each side.
Similarly, the green solid line represents the ground truth mean, while the green dashed lines represent two standard deviations for the “oracle” GP.
The figure demonstrates that the CNP performs quite well in this setting.
As more data is observed, the predictions become tighter, as we would hope.
Moreover, we can see that the CNP predictions quite accurately track the ground truth predictive distribution.</p>
<p>That being said, looking closely we can see some signs that resemble underfitting: for example, the predictive mean does not pass through all the context points, despite there being no noise in the data-generating distribution.
The underfitting becomes abundantly clear when considering more complicated kernels, such as a periodic kernel.</p>
<div class="figure align-default" id="cnp-periodic-text">
<a class="reference internal image-reference" href="../_images/CNP_periodic.gif"><img alt="CNP on GP with Periodic kernel" src="../_images/CNP_periodic.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of CNPs (Blue) and the oracle GP (Green) with Periodic kernel.</span><a class="headerlink" href="#cnp-periodic-text" title="Permalink to this image">¶</a></p>
</div>
<p>Here we see that the CNP completely fails to model the predictive distribution: the mean function is overly smooth, hardly passes through the context points, and no notion of periodicity seems to have been learned.
Moreover, the uncertainty seems constant, and is significantly overestimated everywhere.
It thus seems reasonable to conclude that the CNP is not expressive enough to accurately model this (more complicated) process.</p>
<p>One potential solution, motivated by the fact that we know CNPs should be able to approximate <em>any</em> mean and variance functions, might be to simply increase capacity of networks <span class="math notranslate nohighlight">\(e_{\boldsymbol\theta}\)</span> and <span class="math notranslate nohighlight">\(d_{\boldsymbol\theta}\)</span>.
Unfortunately, it turns out that CNPs’ modelling power scales quite poorly with the capacity of its networks.
A more promising avenue, which we explore next, is to consider the inductive biases of its architectures.</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details and (many more) plots, along with code for constructing and training, CNPs can be found in <a class="reference internal" href="../reproducibility/CNP.html"><span class="doc">CNP Notebook</span></a></p>
</div>
</div>
<div class="section" id="attentive-conditional-neural-process-attncnp">
<h2>Attentive Conditional Neural Process (AttnCNP)<a class="headerlink" href="#attentive-conditional-neural-process-attncnp" title="Permalink to this headline">¶</a></h2>
<p>An important observation, made by <a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id3">[KMS+19]</a>, is that in the CNP parameterisation, all points in the target set share a single, global representation <span class="math notranslate nohighlight">\(R\)</span>.
In other words, the CNP employs the same, <em>target independent representation</em> when making predictions for any target set location.
This implies that all points in the context set have the same “importance”, regardless of the location at which a prediction is being made.
Intuitively, it may seem natural that different points in the context set may be more relevant to predictions in different regions of <span class="math notranslate nohighlight">\(X\)</span>-space.
<a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id4">[KMS+19]</a> propose to address this issue by using a target-specific representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span>, as illustrated in <code class="xref std std-numref docutils literal notranslate"><span class="pre">computational_graph_AttnCNPs_text</span></code>.</p>
<div class="figure align-default" id="computational-graph-attncnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_AttnCNPs1.svg"><img alt="Computational graph of AttnCNP" src="../_images/computational_graph_AttnCNPs1.svg" width="300em" /></a>
<p class="caption"><span class="caption-text">Computational graph for AttnCNP.</span><a class="headerlink" href="#computational-graph-attncnps-text" title="Permalink to this image">¶</a></p>
</div>
<div class="dropdown tip admonition">
<p class="admonition-title">Note</p>
<p>Another perspective, which we will be useful later on, is that the representation <span class="math notranslate nohighlight">\(R\)</span> is actually a function of the form <span class="math notranslate nohighlight">\(R : \mathcal{X} \to \mathbb{R}^{dr}\)</span> instead of a vector.
This function will be queried at the target position <span class="math notranslate nohighlight">\(x^{(t)}\)</span> to yield a target specific vector representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span>.</p>
</div>
<p>To achieve this, <a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id5">[KMS+19]</a> propose the Attentive CNP (AttnCNP<a class="footnote-reference brackets" href="#attncnp" id="id6">1</a>), which employs an <em>attention mechanism</em> (<a class="bibtex reference internal" href="../zbibliography.html#bahdanau2014neural" id="id7">[BCB14]</a>) to compute <span class="math notranslate nohighlight">\(R^{(t)}\)</span>.
There are many great resources available about the use of attention mechanisms in machine learning [(LINKS TO PAPERS / BLOG POSTS ON ATTENTION?], and we encourage readers unfamiliar with the concept to look through these.
For our purposes, it suffices to think of attention mechanisms as learning to <em>attend</em> to specific parts of an input that are particularly relevant to the desired output, giving them more <em>weight</em> than others when making a prediction.</p>
<div class="dropdown tip admonition">
<p class="admonition-title">Note</p>
<p>To see that attention mechanisms satisfy permutation invariance, we must provide a more explicit form for the resulting representations.
With an attention mechanism, we can express these forms as</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
R^{(t)} = \sum_{c=1}^{| \mathcal{C} |} w_{\boldsymbol \theta}(x^{(c)}, x^{(t)}) R^{(c)},
\end{align}
\]</div>
<p>where <span class="math notranslate nohighlight">\(w_{\boldsymbol \theta}(x^{(c)}, x^{(t)})\)</span> is the weight output by the attention mechanism, and <span class="math notranslate nohighlight">\(R^{(c)} = e_{\boldsymbol \theta}(x^{(c)}, y^{(c)})\)</span> as before.
Thus, we can see that the resulting representation is simply a weighted sum, which is permutation invariant due to the commutativity of the summation operation.</p>
<p>From this view, we can also immediately see that the AttnCNP is a strict generalisation of the CNP, in the sense that the AttnCNP recovers the CNP if we set <span class="math notranslate nohighlight">\(w_{\boldsymbol \theta}(x^{(c)}, x^{(t)}) = \frac{1}{| \mathcal{C} |}\)</span>, for any <span class="math notranslate nohighlight">\(x^{(t)}\)</span>.</p>
</div>
<p>In the AttnCNP, we can think of the attention mechanism as providing a set of weights for <span class="math notranslate nohighlight">\(\{ w^{(c)}(x^{(t)}) \}\)</span>, one for each point in the context set.
Importantly, this set of weights is different for (and depends directly on) every target location!
To illustrate how this alleviates underfitting, imagine that our context set contains to points which are “very far” apart in <span class="math notranslate nohighlight">\(X\)</span>-space.
When making predictions close to the first point, we should largely ignore the <span class="math notranslate nohighlight">\(R^{(2)}\)</span>, since it contains little information about this region of <span class="math notranslate nohighlight">\(X\)</span>-space compared to <span class="math notranslate nohighlight">\(R^{(1)}\)</span>.
The converse is true when making predictions near the second point.
Attention allows us to parameterise and generalise this intuition, and learn it directly from the data!</p>
<div class="dropdown important admonition">
<p class="admonition-title">Computational Complexity</p>
<p>Note that attention comes at the cost of additional computational complexity: from  <span class="math notranslate nohighlight">\(\mathcal{O}(T+C)\)</span> to <span class="math notranslate nohighlight">\(\mathcal{O}(C(C*T))\)</span> although it can be efficiently parallelised on GPUs.
For every target we now have to attend to a representation at each context element (cross attention).
For each target point a representation <span class="math notranslate nohighlight">\(R^{(t)}\)</span> is then computed using cross-attention <span class="math notranslate nohighlight">\(\mathcal{O}(C*T)\)</span>.
In addition, the context representations (target independent) usually first go through a self attention layer, where each context point attends to one another <span class="math notranslate nohighlight">\(\mathcal{O}(C^2)\)</span>.
Putting all together that gives  <span class="math notranslate nohighlight">\(\mathcal{O}(C(C*T))\)</span> computational complexity.</p>
</div>
<p>Without further ado, let us see how the AttnCNP performs in practice.
We will first evaluate it on GPs from different kernels (RBF, periodic, and Noisy Matern).</p>
<div class="figure align-default" id="attncnp-single-gp-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_single_gp1.gif"><img alt="AttnCNP on GPs with RBF, periodic, noisy Matern kernel" src="../_images/AttnCNP_single_gp1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of AttnCNPs (Blue) and the oracle GP (Green) with RBF,Periodic,noisy Matern kernel.</span><a class="headerlink" href="#attncnp-single-gp-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">AttnCNP_single_gp_text</span></code> demonstrates that, as desired, AttnCNP alleviates many of the underfitting issues of the CNP, and generally performs much better on the challenging kernels.
However, looking closely at the resulting fits, we can still see some dissatisfying properties:</p>
<ul class="simple">
<li><p>the fit on the Periodic kernel is still not <em>great</em>, and</p></li>
<li><p>looking carefully, we see that the AttnCNP has a posterior predictive with “kinks”, i.e., it is not very smooth. Note that kinks usually appear between 2 context points. This leads us to believe that they are a consequence of the AttnCNP abruptly changing its attention from one context point to the other (due to the exponential in the softmax used to parameterise the attention mechanism).</p></li>
</ul>
<p>Overall, AttnCNP performs quite well in this setting.
Next, we turn our attention (pun intended) to a more realistic setting, where we do not have access to the underlying data generating process: images.
In our experiments, we consider images as functions from the 2d integer grid (denoted <span class="math notranslate nohighlight">\(\mathbb{Z}^2\)</span>) to pixel space (this can be grey-scale or RGB, depending on the context).
When thinking about images as functions, it makes sense to reference the underlying stochastic process that generated them, though of course we can not express this process, nor have access to its ground truth posterior predictive distributions.
Just as in the 1D case, our goal is to model the posterior distribution of target pixels (typically the complete image) given a few context pixels.</p>
<div class="figure align-default" id="attncnp-img-interp-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_img_interp.gif"><img alt="AttnCNP on CelebA and MNIST" src="../_images/AttnCNP_img_interp.gif" style="width: 30em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of an AttnCNP for CelebA <span class="math notranslate nohighlight">\(32\times32\)</span> and MNIST.</span><a class="headerlink" href="#attncnp-img-interp-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">AttnCNP_img_interp_text</span></code> illustrates the performance of the AttnCNP on image reconstruction tasks with CelebA (left) and MNIST (right).
The results are quite impressive, and we can see that the AttnCNP is able to learn complicated structure in the underlying process, and produce compelling reconstructions of the data when faced with small context sets, and also structured obfuscation of the image that is different from what was observed during training.
The image experiments hammer home an important advantage of the NPF over other approaches to modelling stochastic processes.
We can see that the same architecture can scale to complicated underlying processes, learning the important properties from the data (rather than requiring intricate kernel design, as in the case of GPs).
Intuitively, we can think of NPF models as implicitly learning these properties, or kernels, from the data, while allowing us to bake in some inductive biases into the architecture of the model.</p>
</div>
<div class="section" id="generalisation-and-extrapolation">
<h2>Generalisation and Extrapolation<a class="headerlink" href="#generalisation-and-extrapolation" title="Permalink to this headline">¶</a></h2>
<p>So far, we have seen that CNPF members can flexibly model a range of stochastic processes, and that we can overcome some of the key limitations by carefully designing the model architectures.
This led us to the AttnCNP, which achieves compelling performance on a range of both GP and image-based tasks.
Next, we consider the question of <em>generalisation</em> and <em>exptrapolation</em> with CNPF members.</p>
<p>One property of GPs is that they can condition predictions on data observed in any region of <span class="math notranslate nohighlight">\(X\)</span>-space.
When training a NPF member, we must specify a bounded range of <span class="math notranslate nohighlight">\(X\)</span> on which data is observed, since we can never sample data from an infinite range.
We know that neural networks are typically quite bad at generalising outside the training distribution, and so we might suspect that CNPF model will not have this appealing property.</p>
<p>Let’s first probe this question in the GP experiments.
To do so, we can examine what happens when trained models are provided with observations from the underlying process, but outside the training range.</p>
<div class="figure align-default" id="attncnp-rbf-extrap-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_rbf_extrap.gif"><img alt="extrapolation of AttnCNP on GPs with RBF kernel" src="../_images/AttnCNP_rbf_extrap.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Extrapolation (red dashes) of posterior predictive of AttnCNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#attncnp-rbf-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">AttnCNP_rbf_extrap_text</span></code> clearly shows that the AttnCNP breaks as soon as the context set contains observations from outside the training range.
In other words, the AttnCNP really was not able to model the the fact that RBF kernel is stationary, i.e., that the absolute position of target points is not important only their relative position compared to context points.</p>
<p>We can also observe this phenomenon in the image setting.
For example let us take an AttnCNP trained on MNIST (augmented with translations) and test it on a larger canvas with 2 digits (Zero Shot Multi MNIST, ZSMM).</p>
<div class="figure align-default" id="attncnp-img-extrap-text">
<a class="reference internal image-reference" href="../_images/AttnCNP_img_extrap.gif"><img alt="AttnCNP on ZSMM" src="../_images/AttnCNP_img_extrap.gif" style="width: 15em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of an AttnCNP for ZSMM.</span><a class="headerlink" href="#attncnp-img-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p>Again we see in <code class="xref std std-numref docutils literal notranslate"><span class="pre">AttnCNP_rbf_extrap_text</span></code> that the model completely breaks in this generalisation task.
This is probably not surprising to anyone who worked with neural nets as the test set is significantly different of the training set, which is challenging.
Despite the challenging nature of the failure mode, it turns out that we can in fact construct NPF members that avoid it.
This leads us to our next CNPF member – the ConvCNP.</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details, training and many more plots in <a class="reference internal" href="../reproducibility/AttnCNP.html"><span class="doc">AttnCNP Notebook</span></a></p>
</div>
</div>
<div class="section" id="convolutional-conditional-neural-process-convcnp">
<h2>Convolutional Conditional Neural Process (ConvCNP)<a class="headerlink" href="#convolutional-conditional-neural-process-convcnp" title="Permalink to this headline">¶</a></h2>
<div class="tip admonition">
<p class="admonition-title">Disclaimer</p>
<p>The authors of this tutorial are co-authors on the ConvCNP paper.</p>
</div>
<p>It turns out that the question of generalisation is closely linked to notions of <em>symmetry</em> and <em>equivariance</em>.
In particular, the type of generalisation we are looking for – that the NPF members be able to condition predictions on data observed anywhere in <span class="math notranslate nohighlight">\(X\)</span>-space – can be mathematically expressed as a property called <em>translation equivariance</em>.
In the <a class="reference internal" href="Theory.html"><span class="doc">Theory</span></a> chapter we provide formal definitions for these notions, but for now the following intuition for translation equivariance (TE) should suffice: if observations are shifted in time or space, then the resulting predictions should be shifted by the same amount.
It turns out that this simple inductive bias, when appropriate, is <em>wildly</em> effective.
Arguably the most prominent example of translation equivariance in machine learning are convolutional neural networks (CNNs), which are built around this simple intuition.</p>
<p>This provides the central motivation behind the ConvCNP <a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id8">[GBF+19]</a>: how can we bake TE into CNPF members, while preserving other desirable aspects of the models?
Hopefully, doing so should lead to CNPF members that exhibit the generalisation capacities we are after, as well as improved performance and <em>parameter efficiency</em> (which is another benefit often associated with baking in TE).
To achieve this, <a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id9">[GBF+19]</a> propose a special form of convolutional layer, which can be seen as an extension of standard convolutions to <em>set-structured</em> inputs.
We refer to such layers as <em>SetConvs</em>.
With this layer, we can then construct ConvCNPs by defining the following design choices (illustrated in <code class="xref std std-numref docutils literal notranslate"><span class="pre">computational_graph_ConvCNPs_text</span></code>):</p>
<ul class="simple">
<li><p>The encoding function is a SetConv layer.</p></li>
<li><p>The aggregation function is a standard convolutional layer.</p></li>
<li><p>The decoder <span class="math notranslate nohighlight">\(d_{\boldsymbol\theta}\)</span> is a standard CNN.</p></li>
</ul>
<div class="dropdown caution admonition">
<p class="admonition-title">Important</p>
<p>The ConvCNP encoder <em>explicitly</em> encodes <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> into a space of functions.
That is, every context set is represented by a <em>continuous</em> function <span class="math notranslate nohighlight">\(X \to \mathbb{R}^{dr}\)</span>.
While this representation is extremely useful, it requires an approximation: since the decoder is a CNN, it operates on <em>discrete</em> inputs.
To enable this, the ConvCNP first <em>discretises</em> the functional representation of the context set before passing it to the decoder.
While this means the forward pass through the ConvCNP can only be approximated, in practice this turns out to not have a detrimental effect on performance.</p>
</div>
<div class="dropdown caution admonition">
<p class="admonition-title">Advanced</p>
<p>One of the key results of <a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id10">[GBF+19]</a> is to show that SetConv layers are both permutation invariant and translation equivariant.
Moreover, <a class="bibtex reference internal" href="../zbibliography.html#gordon2019convolutional" id="id11">[GBF+19]</a> demonstrate that <em>any</em> (continuous) permutation invariance and TE function can be represented by a ConvCNP.
The proof relies on first extending the DeepSets work of <a class="bibtex reference internal" href="../zbibliography.html#zaheer2017deep" id="id12">[ZKR+17]</a> to include TE as well.
In the <a class="reference internal" href="Theory.html"><span class="doc">Theory</span></a> chapter, we provide a sketch of this proof.</p>
</div>
<div class="dropdown important admonition">
<p class="admonition-title">Computational Complexity</p>
<p><span class="math notranslate nohighlight">\(\mathcal{O}(U(C*T))\)</span> […].</p>
</div>
<div class="figure align-default" id="computational-graph-convcnps-text">
<a class="reference internal image-reference" href="../_images/computational_graph_ConvCNPs1.svg"><img alt="Computational graph ConvCNP" height="300em" src="../_images/computational_graph_ConvCNPs1.svg" /></a>
<p class="caption"><span class="caption-text">Computational graph of ConvCNP [to keep ? to simplify ?].</span><a class="headerlink" href="#computational-graph-convcnps-text" title="Permalink to this image">¶</a></p>
</div>
<p>Now that we have constructed a translation equivariant CNPF, we can test it in the more challenging extrapolation regime.
We begin with the same set of GP experiments, but this time already including data observed from outside the original training range.</p>
<div class="figure align-default" id="convcnp-single-gp-extrap-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_single_gp_extrap1.gif"><img alt="../_images/ConvCNP_single_gp_extrap1.gif" src="../_images/ConvCNP_single_gp_extrap1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Extrapolation (red dashes) of posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with (top) RBF, (center) periodic, and (bottom) Noisy Matern kernel.</span><a class="headerlink" href="#convcnp-single-gp-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_single_gp_extrap_text</span></code> demonstrates that the ConvCNP indeed performs very well!
In particular, we can see that:</p>
<ul class="simple">
<li><p>Like the use of attention, the TE inductive bias also helps the model avoid the tendency to underfit the data.</p></li>
<li><p>Unlike the other members of the CNPF, the ConvCNP is able to extrapolate outside of the training range.
Note that this is a direct consequence of TE.</p></li>
<li><p>Unlike attention, the ConvCNP produces smooth mean and variance functions, avoiding the “kinks” introduced by the AttnCNP.</p></li>
<li><p>The ConvCNP is able to learn about the underlying structure in the periodic kernel.
We can see this by noting that it produces periodic predictions, even “far” away from the observed data.</p></li>
</ul>
<div class="dropdown important admonition warning">
<p class="admonition-title">Warning</p>
<p>The periodic kernel example is a little misleading, indeed the ConvCNP does not recover the underlying GP.
In fact, we know that it cannot exactly recover the underlying process, because it has a <em>bounded receptive field</em>, and as a result can only model local periodicity.
This is best seen when considering a much larger target interval (<span class="math notranslate nohighlight">\([-2,14]\)</span> instead of <span class="math notranslate nohighlight">\([0,4]\)</span>), as below.</p>
<div class="figure align-default" id="convcnp-periodic-large-extrap-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_periodic_large_extrap1.gif"><img alt="ConvCNP on single images" src="../_images/ConvCNP_periodic_large_extrap1.gif" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Large extrapolation (red dashes) of posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with periodic kernel.</span><a class="headerlink" href="#convcnp-periodic-large-extrap-text" title="Permalink to this image">¶</a></p>
</div>
<p>In fact, this is true for any of the GPs above, all of which have infinite receptive fields, meaning that no model with a bounded field (such as the ConvCNP) can ever exactly recover them.
This discussion alludes to one of the key design choices of the ConvCNP, which is the size of its receptive field.
Note that, unlike standard CNNs, the resulting receptive field does not only depend on the CNN architecture, but also on the granularity of the discretisation employed on the functional representation.
Thus, when designing ConvCNP architectures, some consideration should be given to the interplay between the discretisation and the architecture of the decoder.</p>
</div>
<p>Let us also examine the performance of the ConvCNP on the more challenging image experiments.
As with the AttnCNP, we consider CelebA and MNIST reconstruction experiments, but also unclude the ZSMM experiments that evaluate the model’s ability to generalise beyond the training data.</p>
<div class="figure align-default" id="convcnp-img-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_img1.gif"><img alt="ConvCNP on CelebA, MNIST, ZSMM" src="../_images/ConvCNP_img1.gif" style="width: 45em;" /></a>
<p class="caption"><span class="caption-text">Posterior predictive of an AttnCNP for CelebA, MNIST, and ZSMM.</span><a class="headerlink" href="#convcnp-img-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_img_text</span></code> we see that the ConvCNP performs quite well on all datasets when the context set is large enough and uniformly sampled, even when extrapolation is needed (ZSMM).
However, performance is less impressive when the context set is very small or when it is structured, e.g., half images.
In our experiments we find that this is more of an issue for the ConvCNP than the AttnCNP (<a class="reference internal" href="../reproducibility/AttnCNP.html#attncnp-img"><span class="std std-numref">Fig. 41</span></a>).
We hypothesise that this happens because the effective receptive field of the former is too small, whilst the AttnCNP has an infinite receptive field, allowing it to make more use of observed pixels far from the target pixel.
This issue can be alleviated by reducing the size of the context set seen during training (to force the model to have a large receptive field), but this solution is somewhat dissatisfying in that it requires tinkering with the training procedure.</p>
<p>Although the zero shot generalisation when performing on ZSMM are encouraging, the task is somewhat artificial.
Let us consider more complex zero shot generalisation tasks.
First, we will evaluate a ConvCNP trained on CelebA128 on an image with multiple faces of different scale and orientation.</p>
<div class="figure align-default" id="convcnp-img-zeroshot-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_img_zeroshot.png"><img alt="Zero shot generalization of ConvCNP to a real picture" src="../_images/ConvCNP_img_zeroshot.png" style="width: 50em;" /></a>
<p class="caption"><span class="caption-text">Zero shot generalization of a ConvCNP trained on CelebA and evaluated on Ellen’s selfie</span><a class="headerlink" href="#convcnp-img-zeroshot-text" title="Permalink to this image">¶</a></p>
</div>
<p>From <code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_img_zeroshot_text</span></code> we see that the model is able to generalise reasonably well to real world data in a zero shot fashion.
Although the previous results look nice, the use-cases are not immediately obvious, as it is not very to have missing pixels.
One possible application is increasing the resolution of an image.
This can be achieved by querying positions “in between” pixels.</p>
<div class="figure align-default" id="convcnp-superes-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_superes.png"><img alt="Increasing image resolution with ConvCNP" src="../_images/ConvCNP_superes.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Increasing the resolution of <span class="math notranslate nohighlight">\(16 \times 16\)</span> CelebA to <span class="math notranslate nohighlight">\(128 \times 128\)</span> with a ConvCNP.</span><a class="headerlink" href="#convcnp-superes-text" title="Permalink to this image">¶</a></p>
</div>
<p><code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_superes_text</span></code> demonstrates such an application.
We see that CNPFs can indeed be used to increase the resolution of an image, even though it was not trained to do so!</p>
<div class="tip admonition">
<p class="admonition-title">Details</p>
<p>Model details, training and many more plots are available in the <a class="reference internal" href="../reproducibility/ConvCNP.html"><span class="doc">ConvCNP Notebook</span></a></p>
</div>
<div class="section" id="issues-with-cnpfs">
<span id="issues-cnpfs"></span><h3>Issues With CNPFs<a class="headerlink" href="#issues-with-cnpfs" title="Permalink to this headline">¶</a></h3>
<p>Let’s take a step back.
So far, we have seen that we can use the factorisation assumption to construct simple members of the CNPF, perhaps the simplest of these being the CNP.
Our first observation was that while the CNP can track underlying processes, it tends to underfit when the processes are more complicated.
We saw that this tendency can be addressed by adding appropriate inductive biases into the paramterisation of the model.
Specifically, the AttnCNP significantly improves upon the CNP by adding an attention mechanism to generate target-specific representations of the context set.
We further saw that the AttnCNP also scales nicely to image-settings.
However, both the CNP and AttnCNP fail to make meaningful predictions when data is observed outside the training range (or when the test distribution is different from training, i.e., in the ZSMM example).
Finally, we saw how including TE as an inductive bias led to well-fitting functions that generalised elegantly to observations outside the training range.</p>
<p>Let us now consider more closely the implications of the factorisation assumption, along with the Gaussian form of predictive distributions.
One immediate consequence of using the Gaussian likelihood is that we cannot recover multi-modal distributions.
To see why this might be an issue, consider making predictions for the MNIST reconstruction experiments.</p>
<div class="figure align-default" id="convcnp-marginal-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_marginal.png"><img alt="Samples from ConvCNP on MNIST and posterior of different pixels" src="../_images/ConvCNP_marginal.png" style="width: 20em;" /></a>
<p class="caption"><span class="caption-text">Samples form the posterior predictive of ConvCNPs on MNIST (left) and posterior predictive of some pixels (right).</span><a class="headerlink" href="#convcnp-marginal-text" title="Permalink to this image">¶</a></p>
</div>
<p>Looking at <code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_marginal_text</span></code>, we might expect that sampling from the predictive distribution of an unobserved pixels sometimes yield completely white values, and sometimes completely black, depending on whether the sample represents, for example, a 3 or a 5.
However, a Gaussian distribution, which is uni-modal (see <code class="xref std std-numref docutils literal notranslate"><span class="pre">ConvCNP_marginal_text</span></code> right), cannot achieve this type of multi-modal behaviour.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Note</p>
<p>One solution to this particular problem might be to employ some other parametric distribution that enables multimodality, for example, a mixture of Gaussians.
While this may solve some issues, we can generalise this point to say that the CNPF requires specifying <em>some parametric form of distribution</em>.
Ideally, what we would like is some parametrisation of the NPF that enables us to recover <em>any</em> form of marginal distribution.</p>
</div>
<p>The other major restriction is the factorisation assumption itself, which has several important implications.
First, it means that the model can not leverage any correlation structure that might exist in the predictive distribution over multiple target sets.
For example imagine that we are modelling samples from an underlying GP.
If the model is making predictions at two target locations that are “close” in <span class="math notranslate nohighlight">\(X\)</span>-space, it seems reasonable that whenever it predicts the first be “high”, it predict something similar for the second, and vice versa.
Yet the factorisation assumption means that the model cannot learn this type of structure.
Another implication is that we can not produce <em>coherent</em> samples from the predictive distribution.
In fact, sampling from the posterior corresponds to adding independent noise to the mean at each target location, resulting in samples that look nothing like the underlying process.</p>
<div class="figure align-default" id="convcnp-rbf-samples-text">
<a class="reference internal image-reference" href="../_images/ConvCNP_rbf_samples.png"><img alt="Sampling from ConvCNP on GP with RBF kernel" src="../_images/ConvCNP_rbf_samples.png" style="width: 35em;" /></a>
<p class="caption"><span class="caption-text">Samples form the posterior predictive of ConvCNPs (Blue) and the oracle GP (Green) with RBF kernel.</span><a class="headerlink" href="#convcnp-rbf-samples-text" title="Permalink to this image">¶</a></p>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">Note</p>
<p>This inability to sample from the predictive may inhibit the deployment of CNPF members from several application areas for which it might otherwise be potentially well-suited.
One such example is the use of Thompson sampling algorithms for e.g., contextual bandits or Bayesian optimisation, which require a model to produce samples.</p>
</div>
<p>In the next chapter, we will see one approach to solving both these issues by treating the representation as a latent variable in the latent Neural Process sub-family.</p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="attncnp"><span class="brackets"><a class="fn-backref" href="#id6">1</a></span></dt>
<dd><p><a class="bibtex reference internal" href="../zbibliography.html#kim2019attentive" id="id13">[KMS+19]</a> only introduced the latent variable model, but one can easily drop the latent variable if not needed.</p>
</dd>
</dl>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois and Jonathan Gordon<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>