

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Latent Neural Process (CNP) &#8212; Neural Process Family</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/mystnb.js"></script>
    <script src="_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Attentive Latent Neural Process (AttnLNP)" href="AttnLNP.html" />
    <link rel="prev" title="Latent NPFs" href="LNPFs.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="index.html">
  
  <img src="_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Neural Process Family</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="CNPFs.html">Conditional NPFs</a>
  </li>
  <li class="active">
    <a href="LNPFs.html">Latent NPFs</a>
  <ul class="nav sidenav_l2">
    <li class="active">
      <a href="">Latent Neural Process (CNP)</a>
    </li>
    <li class="">
      <a href="AttnLNP.html">Attentive Latent Neural Process (AttnLNP)</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="Additional.html">Additional</a>
  </li>
  <li class="">
    <a href="zbibliography.html">Bibliography</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="_sources/LNP.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Source interaction buttons -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#initialization" class="nav-link">Initialization</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#training" class="nav-link">Training</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#inference" class="nav-link">Inference</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#gps-dataset" class="nav-link">GPs Dataset</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h5">
            <a href="#samples-from-a-single-gp" class="nav-link">Samples from a single GP</a>
        </li>
    
        <li class="nav-item toc-entry toc-h5">
            <a href="#samples-from-gps-with-varying-kernel-hyperparameters" class="nav-link">Samples from GPs with varying kernel hyperparameters</a>
        </li>
    
        <li class="nav-item toc-entry toc-h5">
            <a href="#samples-from-gps-with-varying-kernels" class="nav-link">Samples from GPs with varying Kernels</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#image-dataset" class="nav-link">Image Dataset</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="latent-neural-process-cnp">
<h1>Latent Neural Process (CNP)<a class="headerlink" href="#latent-neural-process-cnp" title="Permalink to this headline">¶</a></h1>
<div class="figure align-default" id="computational-graph-lnps">
<a class="reference internal image-reference" href="images/computational_graph_LNPs.svg"><img alt="images/computational_graph_LNPs.svg" height="250px" src="images/computational_graph_LNPs.svg" /></a>
<p class="caption"><span class="caption-number">Fig. 15 </span><span class="caption-text">Computational graph for Conditional Neural Processes.</span><a class="headerlink" href="#computational-graph-lnps" title="Permalink to this image">¶</a></p>
</div>
<p>[…]</p>
<div class="section" id="initialization">
<h2>Initialization<a class="headerlink" href="#initialization" title="Permalink to this headline">¶</a></h2>
<p>Let’s load the <a class="reference internal" href="Datasets.html"><span class="doc">data</span></a> and define the context target splitter.
Here, we select uniformly between 0.0 and 0.5 context points and use all points as target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">npf.utils.datasplit</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CntxtTrgtGetter</span><span class="p">,</span>
    <span class="n">GetRandomIndcs</span><span class="p">,</span>
    <span class="n">GridCntxtTrgtGetter</span><span class="p">,</span>
    <span class="n">RandomMasker</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">utils.data</span> <span class="kn">import</span> <span class="n">cntxt_trgt_collate</span>
<span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">get_all_gp_datasets</span><span class="p">,</span> <span class="n">get_img_datasets</span>

<span class="c1"># DATASETS</span>
<span class="c1"># gp</span>
<span class="n">gp_datasets</span><span class="p">,</span> <span class="n">gp_test_datasets</span><span class="p">,</span> <span class="n">gp_valid_datasets</span> <span class="o">=</span> <span class="n">get_all_gp_datasets</span><span class="p">()</span>
<span class="c1"># image</span>
<span class="n">img_datasets</span><span class="p">,</span> <span class="n">img_test_datasets</span> <span class="o">=</span> <span class="n">get_img_datasets</span><span class="p">([</span><span class="s2">&quot;celeba32&quot;</span><span class="p">,</span> <span class="s2">&quot;mnist&quot;</span><span class="p">,</span> <span class="s2">&quot;zsmms&quot;</span><span class="p">])</span>

<span class="c1"># CONTEXT TARGET SPLIT</span>
<span class="n">get_cntxt_trgt_1d</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">CntxtTrgtGetter</span><span class="p">(</span><span class="n">contexts_getter</span><span class="o">=</span><span class="n">GetRandomIndcs</span><span class="p">(</span><span class="n">min_n_indcs</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">max_n_indcs</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">get_cntxt_trgt_2d</span> <span class="o">=</span> <span class="n">cntxt_trgt_collate</span><span class="p">(</span>
    <span class="n">GridCntxtTrgtGetter</span><span class="p">(</span><span class="n">context_masker</span><span class="o">=</span><span class="n">RandomMasker</span><span class="p">(</span><span class="n">min_nnz</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">max_nnz</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s now define the models. For both the 1D and 2D case we will be using the following:</p>
<ul class="simple">
<li><p><strong>Encoder</strong> <span class="math notranslate nohighlight">\(\mathrm{e}_{\boldsymbol{\theta}}\)</span> : a 1-hidden layer MLP that encodes the features (<span class="math notranslate nohighlight">\(\{x^{(i)}\} \mapsto \{x_{transformed}^{(i)}\}\)</span>), followed by a 2 hidden layer MLP that encodes each feature-value pair (<span class="math notranslate nohighlight">\(\{x_{transformed}^{(i)}, y^{(i)}\} \mapsto \{R^{(i)}\}\)</span>).</p></li>
<li><p><strong>Aggregator</strong> <span class="math notranslate nohighlight">\(\mathrm{Agg}\)</span>: mean operator […] latent, gaussian, raparametrization […].</p></li>
<li><p><strong>Decoder</strong> <span class="math notranslate nohighlight">\(\mathrm{d}_{\boldsymbol{\theta}}\)</span>: a 4 hidden layer MLP that predicts the distribution of the target value given the global representation and target context (<span class="math notranslate nohighlight">\(\{R, x^{(t)}\} \mapsto \{\mu^{(t)}, \sigma^{2(t)}\}\)</span>).</p></li>
</ul>
<p>All hidden representations will be of 128 dimensions besides the encoder which is has width <span class="math notranslate nohighlight">\(128*2\)</span> for the 1D case and <span class="math notranslate nohighlight">\(128*3\)</span> for the 2D case (to have similar number of parameters than other NPFs)s.</p>
<p>For more details about all the possible parameters, refer to the docstrings of <code class="docutils literal notranslate"><span class="pre">LNP</span></code> and the base class <code class="docutils literal notranslate"><span class="pre">LatentNeuralProcessFamily</span></code>.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># LNP Docstring</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">LNP</span>

<span class="nb">print</span><span class="p">(</span><span class="n">LNP</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
    (Latent) Neural process from [1].

    Parameters
    ----------
    x_dim : int
        Dimension of features.

    y_dim : int
        Dimension of y values.

    encoded_path : {&quot;latent&quot;, &quot;both&quot;}
        Which path(s) to use:
        - `&quot;latent&quot;`  the decoder gets a sample latent representation as input as in [1].
        - `&quot;both&quot;` concatenates both the deterministic and sampled latents as input to the decoder [2].

    kwargs : 
        Additional arguments to `ConditionalNeuralProcess` and `NeuralProcessFamily`.

    References
    ----------
    [1] Garnelo, Marta, et al. &quot;Neural processes.&quot; arXiv preprint
        arXiv:1807.01622 (2018).
    [2] Kim, Hyunjik, et al. &quot;Attentive neural processes.&quot; arXiv preprint
        arXiv:1901.05761 (2019).
    
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># NeuralProcessFamily Docstring</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">LatentNeuralProcessFamily</span>

<span class="nb">print</span><span class="p">(</span><span class="n">LatentNeuralProcessFamily</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Base class for members of the latent neural process (sub-)family.
    
    Parameters
    ----------
    *args:
        Positional arguments to `NeuralProcessFamily`.

    encoded_path : {&quot;latent&quot;, &quot;both&quot;}
        Which path(s) to use:
        - `&quot;latent&quot;` uses latent : the decoder gets a sample latent representation as input.
        - `&quot;both&quot;` concatenates both the deterministic and sampled latents as input to the decoder.

    is_q_zCct : bool, optional
        Whether to infer Z using q(Z|cntxt,trgt) instead of q(Z|cntxt). This requires the loss 
        to perform some type of importance sampling. Only used if `encoded_path in {&quot;latent&quot;, &quot;both&quot;}`.

    n_z_samples_train : int or scipy.stats.rv_frozen, optional 
        Number of samples from the latent during training. Only used if `encoded_path in {&quot;latent&quot;, &quot;both&quot;}`.
        Can also be a scipy random variable , which is useful if the number of samples has to be stochastic, for 
        example when using `SUMOLossNPF`.

    n_z_samples_test : int or scipy.stats.rv_frozen, optional 
        Number of samples from the latent during testing. Only used if `encoded_path in {&quot;latent&quot;, &quot;both&quot;}`.
        Can also be a scipy random variable , which is useful if the number of samples has to be stochastic, for 
        example when using `SUMOLossNPF`.

    LatentEncoder : nn.Module, optional
        Encoder which maps r -&gt; z_suffstat. It should be constructed via
        `LatentEncoder(r_dim, n_out)`.  If `None` uses an MLP.

    LatentDistribution : torch.distributions.Distribution, optional
        Latent distribution. The input to the constructor are currently two values  : `loc` and `scale`, 
        that are preprocessed by `q_z_loc_transformer` and `q_z_loc_transformer`.

    q_z_loc_transformer : callable, optional
        Transformation to apply to the predicted location (e.g. mean for Gaussian)
        of Y_trgt.

    q_z_scale_transformer : callable, optional
        Transformation to apply to the predicted scale (e.g. std for Gaussian) of
        Y_trgt. The default follows [3] by using a minimum of 0.1 and maximum of 1.

    **kwargs:
        Additional arguments to `NeuralProcessFamily`.
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="kn">from</span> <span class="nn">npf.architectures</span> <span class="kn">import</span> <span class="n">MLP</span><span class="p">,</span> <span class="n">merge_flat_input</span>
<span class="kn">from</span> <span class="nn">utils.helpers</span> <span class="kn">import</span> <span class="n">count_parameters</span>

<span class="n">R_DIM</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">is_q_zCct</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># will use ELBO =&gt; importance sampling</span>
    <span class="n">n_z_samples_train</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_z_samples_test</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">XEncoder</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span>
    <span class="n">Decoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and R so merge them</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">r_dim</span><span class="o">=</span><span class="n">R_DIM</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># 1D case</span>
<span class="n">model_1d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">LNP</span><span class="p">,</span>
    <span class="n">x_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">y_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">XYEncoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and y so merge them</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># image (2D) case</span>
<span class="n">model_2d</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
    <span class="n">LNP</span><span class="p">,</span>
    <span class="n">x_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">XYEncoder</span><span class="o">=</span><span class="n">merge_flat_input</span><span class="p">(</span>  <span class="c1"># MLP takes single input but we give x and y so merge them</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="n">n_hidden_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">R_DIM</span> <span class="o">*</span> <span class="mi">3</span><span class="p">),</span> <span class="n">is_sum_merge</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="o">**</span><span class="n">KWARGS</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># don&#39;t add y_dim yet because depends on data</span>

<span class="n">n_params_1d</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model_1d</span><span class="p">())</span>
<span class="n">n_params_2d</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">model_2d</span><span class="p">(</span><span class="n">y_dim</span><span class="o">=</span><span class="mi">3</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number Parameters (1D): </span><span class="si">{</span><span class="n">n_params_1d</span><span class="si">:</span><span class="s2">,d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number Parameters (2D): </span><span class="si">{</span><span class="n">n_params_2d</span><span class="si">:</span><span class="s2">,d</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Number Parameters (1D): 301,634
Number Parameters (2D): 417,286
</pre></div>
</div>
</div>
</div>
<p>More parameters than CNP because need a MLP that maps <span class="math notranslate nohighlight">\(R \to Z\)</span></p>
<div class="section" id="training">
<h3>Training<a class="headerlink" href="#training" title="Permalink to this headline">¶</a></h3>
<p>The main function for training is <code class="docutils literal notranslate"><span class="pre">train_models</span></code> which trains a dictionary of models on a dictionary of datasets and returns all the trained models.
See its docstring for possible parameters.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">skorch</span>
<span class="kn">from</span> <span class="nn">npf</span> <span class="kn">import</span> <span class="n">ELBOLossLNPF</span>
<span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">add_y_dim</span>
<span class="kn">from</span> <span class="nn">utils.train</span> <span class="kn">import</span> <span class="n">train_models</span>

<span class="n">KWARGS</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">is_retrain</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># whether to load precomputed model or retrain</span>
    <span class="n">criterion</span><span class="o">=</span><span class="n">ELBOLossLNPF</span><span class="p">,</span>  <span class="c1"># (approx) conditional ELBO Loss</span>
    <span class="n">chckpnt_dirname</span><span class="o">=</span><span class="s2">&quot;results/npfs/ntbks/&quot;</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="c1"># use GPU if available</span>
    <span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
    <span class="n">decay_lr</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>  <span class="c1"># decrease learning rate by 10 during training</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="p">)</span>


<span class="c1"># 1D</span>
<span class="n">trainers_1d</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">gp_datasets</span><span class="p">,</span>
    <span class="p">{</span><span class="s2">&quot;LNP&quot;</span><span class="p">:</span> <span class="n">model_1d</span><span class="p">},</span>
    <span class="n">test_datasets</span><span class="o">=</span><span class="n">gp_test_datasets</span><span class="p">,</span>
    <span class="n">valid_datasets</span><span class="o">=</span><span class="n">gp_valid_datasets</span><span class="p">,</span>
    <span class="n">iterator_train__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_1d</span><span class="p">,</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>


<span class="c1"># 2D</span>
<span class="n">trainers_2d</span> <span class="o">=</span> <span class="n">train_models</span><span class="p">(</span>
    <span class="n">img_datasets</span><span class="p">,</span>
    <span class="n">add_y_dim</span><span class="p">({</span><span class="s2">&quot;LNP&quot;</span><span class="p">:</span> <span class="n">model_2d</span><span class="p">},</span> <span class="n">img_datasets</span><span class="p">),</span>  <span class="c1"># y_dim (channels) depend on data</span>
    <span class="n">test_datasets</span><span class="o">=</span><span class="n">img_test_datasets</span><span class="p">,</span>
    <span class="n">train_split</span><span class="o">=</span><span class="n">skorch</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">CVSplit</span><span class="p">(</span><span class="mf">0.1</span><span class="p">),</span>  <span class="c1"># use 10% of training for valdiation</span>
    <span class="n">iterator_train__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_2d</span><span class="p">,</span>
    <span class="n">iterator_valid__collate_fn</span><span class="o">=</span><span class="n">get_cntxt_trgt_2d</span><span class="p">,</span>
    <span class="o">**</span><span class="n">KWARGS</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading RBF_Kernel/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>RBF_Kernel/LNP/run_0 | best epoch: 49 | train loss: 126.5962 | valid loss: 118.9602 | test log likelihood: -118.2876
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading Periodic_Kernel/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Periodic_Kernel/LNP/run_0 | best epoch: 49 | train loss: 126.0286 | valid loss: 125.3654 | test log likelihood: -124.2152
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading Matern_Kernel/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Matern_Kernel/LNP/run_0 | best epoch: 44 | train loss: 139.8478 | valid loss: 132.3145 | test log likelihood: -132.5985
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading Noisy_Matern_Kernel/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Noisy_Matern_Kernel/LNP/run_0 | best epoch: 42 | train loss: 158.093 | valid loss: 151.2483 | test log likelihood: -152.3913
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading Vary_Matern_Kernel/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>Vary_Matern_Kernel/LNP/run_0 | best epoch: 50 | train loss: 83.7429 | valid loss: 73.1572 | test log likelihood: -68.6267
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading All_Kernels/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>All_Kernels/LNP/run_0 | best epoch: 50 | train loss: 145.9605 | valid loss: 141.7223 | test log likelihood: -141.2028
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading celeba32/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>celeba32/LNP/run_0 | best epoch: 50 | train loss: -3199.9146 | valid loss: -3281.2558 | test log likelihood: 3270.982
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading mnist/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>mnist/LNP/run_0 | best epoch: 48 | train loss: -2539.6615 | valid loss: -2580.5693 | test log likelihood: 2573.5326
</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>
--- Loading zsmms/LNP/run_0 ---

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>zsmms/LNP/run_0 | best epoch: 48 | train loss: -2406.9176 | valid loss: -2449.2154 | test log likelihood: -150168.614
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h3>
<div class="section" id="gps-dataset">
<h4>GPs Dataset<a class="headerlink" href="#gps-dataset" title="Permalink to this headline">¶</a></h4>
<div class="section" id="samples-from-a-single-gp">
<h5>Samples from a single GP<a class="headerlink" href="#samples-from-a-single-gp" title="Permalink to this headline">¶</a></h5>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">plot_multi_posterior_samples_1d</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">giffify</span>


<span class="k">def</span> <span class="nf">multi_posterior_gp_gif</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">giffify</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;jupyter/gifs/</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.gif&quot;</span><span class="p">,</span>
        <span class="n">gen_single_fig</span><span class="o">=</span><span class="n">plot_multi_posterior_samples_1d</span><span class="p">,</span>
        <span class="n">sweep_parameter</span><span class="o">=</span><span class="s2">&quot;n_cntxt&quot;</span><span class="p">,</span>
        <span class="c1"># sweep of context points for GIF</span>
        <span class="n">sweep_values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>  <span class="c1"># fix for GIF</span>
        <span class="n">trainers</span><span class="o">=</span><span class="n">trainers</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
        <span class="n">is_plot_real</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>  <span class="c1"># don&#39;t plot sampled function</span>
        <span class="n">plot_config_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">set_kwargs</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">ylim</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]),</span> <span class="n">rc</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;legend.loc&quot;</span><span class="p">:</span> <span class="s2">&quot;upper right&quot;</span><span class="p">}</span>
        <span class="p">),</span>  <span class="c1"># fix for GIF</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">filter_single_gp</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;All&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;Vary&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)}</span>


<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;LNP_single_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">filter_single_gp</span><span class="p">(</span><span class="n">gp_datasets</span><span class="p">),</span>  <span class="c1"># will resample from it =&gt; not on train</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>  <span class="c1"># 50 samples from the latent</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="lnp-single-gp">
<a class="reference internal image-reference" href="_images/LNP_single_gp.gif"><img alt="_images/LNP_single_gp.gif" src="_images/LNP_single_gp.gif" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 16 </span><span class="caption-text">[…] understand is how well NPFs can model a ground truth GP […].</span><a class="headerlink" href="#lnp-single-gp" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#lnp-single-gp"><span class="std std-numref">Fig. 16</span></a> we see that […]</p>
</div>
<div class="section" id="samples-from-gps-with-varying-kernel-hyperparameters">
<h5>Samples from GPs with varying kernel hyperparameters<a class="headerlink" href="#samples-from-gps-with-varying-kernel-hyperparameters" title="Permalink to this headline">¶</a></h5>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">filter_hyp_gp</span><span class="p">(</span><span class="n">d</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="s2">&quot;Vary&quot;</span> <span class="ow">in</span> <span class="n">k</span><span class="p">)}</span>


<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;LNP_vary_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">filter_hyp_gp</span><span class="p">(</span><span class="n">trainers_1d</span><span class="p">),</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">filter_hyp_gp</span><span class="p">(</span><span class="n">gp_datasets</span><span class="p">),</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="lnp-vary-gp">
<a class="reference internal image-reference" href="_images/LNP_vary_gp.gif"><img alt="_images/LNP_vary_gp.gif" src="_images/LNP_vary_gp.gif" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 17 </span><span class="caption-text">[…] understand is how well NPFs can model a ground truth GP […].</span><a class="headerlink" href="#lnp-vary-gp" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#lnp-vary-gp"><span class="std std-numref">Fig. 17</span></a> we see that […]</p>
</div>
<div class="section" id="samples-from-gps-with-varying-kernels">
<h5>Samples from GPs with varying Kernels<a class="headerlink" href="#samples-from-gps-with-varying-kernels" title="Permalink to this headline">¶</a></h5>
<p>As we have seen in <a class="reference internal" href="Datasets.html"><span class="doc">data</span></a>, the dataset with varying kernel simply merged all the datasets with a single kernel.
We will now test each separately. To see how the LNP can recover the ground truth GP even though it was trained with samples from different kernels (including the correct one).</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># data with varying kernels simply merged single kernels</span>
<span class="n">single_gp_datasets</span> <span class="o">=</span> <span class="n">filter_single_gp</span><span class="p">(</span><span class="n">gp_datasets</span><span class="p">)</span>

<span class="c1"># use same trainer for all, but have to change their name to be the same as datasets</span>
<span class="n">base_trainer_name</span> <span class="o">=</span> <span class="s2">&quot;All_Kernels/LNP/run_0&quot;</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">trainers_1d</span><span class="p">[</span><span class="n">base_trainer_name</span><span class="p">]</span>
<span class="n">replicated_trainers</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">single_gp_datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">replicated_trainers</span><span class="p">[</span><span class="n">base_trainer_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;All_Kernels&quot;</span><span class="p">,</span> <span class="n">name</span><span class="p">)]</span> <span class="o">=</span> <span class="n">trainer</span>

<span class="n">multi_posterior_gp_gif</span><span class="p">(</span>
    <span class="s2">&quot;LNP_kernel_gp&quot;</span><span class="p">,</span>
    <span class="n">trainers</span><span class="o">=</span><span class="n">replicated_trainers</span><span class="p">,</span>
    <span class="n">datasets</span><span class="o">=</span><span class="n">single_gp_datasets</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="lnp-kernel-gp">
<a class="reference internal image-reference" href="_images/LNP_kernel_gp.gif"><img alt="_images/LNP_kernel_gp.gif" src="_images/LNP_kernel_gp.gif" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 18 </span><span class="caption-text">[…] understand is how well NPFs can model a ground truth GP […].</span><a class="headerlink" href="#lnp-kernel-gp" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#lnp-kernel-gp"><span class="std std-numref">Fig. 18</span></a> we see that […]</p>
</div>
</div>
<div class="section" id="image-dataset">
<h4>Image Dataset<a class="headerlink" href="#image-dataset" title="Permalink to this headline">¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">plot_multi_posterior_samples_imgs</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">giffify</span>


<span class="k">def</span> <span class="nf">multi_posterior_imgs_gif</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">trainers</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">giffify</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;jupyter/gifs/</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">.gif&quot;</span><span class="p">,</span>
        <span class="n">gen_single_fig</span><span class="o">=</span><span class="n">plot_multi_posterior_samples_imgs</span><span class="p">,</span>
        <span class="n">sweep_parameter</span><span class="o">=</span><span class="s2">&quot;n_cntxt&quot;</span><span class="p">,</span>
        <span class="c1"># sweep of context points for GIF</span>
        <span class="n">sweep_values</span><span class="o">=</span><span class="p">[</span>
            <span class="mi">0</span><span class="p">,</span>
            <span class="mf">0.001</span><span class="p">,</span>
            <span class="mf">0.003</span><span class="p">,</span>
            <span class="mf">0.005</span><span class="p">,</span>
            <span class="mf">0.007</span><span class="p">,</span>
            <span class="mf">0.01</span><span class="p">,</span>
            <span class="mf">0.02</span><span class="p">,</span>
            <span class="mf">0.03</span><span class="p">,</span>
            <span class="mf">0.05</span><span class="p">,</span>
            <span class="mf">0.07</span><span class="p">,</span>
            <span class="mf">0.1</span><span class="p">,</span>
            <span class="mf">0.15</span><span class="p">,</span>
            <span class="mf">0.2</span><span class="p">,</span>
            <span class="mf">0.3</span><span class="p">,</span>
            <span class="mf">0.5</span><span class="p">,</span>
            <span class="mf">0.7</span><span class="p">,</span>
            <span class="mf">0.99</span><span class="p">,</span>
            <span class="s2">&quot;hhalf&quot;</span><span class="p">,</span>
            <span class="s2">&quot;vhalf&quot;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>  <span class="c1"># fix for GIF</span>
        <span class="n">trainers</span><span class="o">=</span><span class="n">trainers</span><span class="p">,</span>
        <span class="n">datasets</span><span class="o">=</span><span class="n">datasets</span><span class="p">,</span>
        <span class="n">n_plots</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>  <span class="c1"># number of samples plots for each data</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>


<span class="n">multi_posterior_imgs_gif</span><span class="p">(</span>
    <span class="s2">&quot;LNP_img&quot;</span><span class="p">,</span> <span class="n">trainers</span><span class="o">=</span><span class="n">trainers_2d</span><span class="p">,</span> <span class="n">datasets</span><span class="o">=</span><span class="n">img_test_datasets</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-default" id="lnp-img">
<a class="reference internal image-reference" href="_images/LNP_img.gif"><img alt="_images/LNP_img.gif" src="_images/LNP_img.gif" style="width: 500px;" /></a>
<p class="caption"><span class="caption-number">Fig. 19 </span><span class="caption-text">[…] dataset img[…].</span><a class="headerlink" href="#lnp-img" title="Permalink to this image">¶</a></p>
</div>
<p>From <a class="reference internal" href="#lnp-img"><span class="std std-numref">Fig. 19</span></a> we see that […]</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">utils.ntbks_helpers</span> <span class="kn">import</span> <span class="n">PRETTY_RENAMER</span>
<span class="kn">from</span> <span class="nn">utils.visualize</span> <span class="kn">import</span> <span class="n">plot_qualitative_with_kde</span>

<span class="n">n_trainers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">trainers_2d</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">trainer</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainers_2d</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">data_name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;/&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="n">img_test_datasets</span><span class="p">[</span><span class="n">data_name</span><span class="p">]</span>

    <span class="n">plot_qualitative_with_kde</span><span class="p">(</span>
        <span class="p">[</span><span class="n">PRETTY_RENAMER</span><span class="p">[</span><span class="n">model_name</span><span class="p">],</span> <span class="n">trainer</span><span class="p">],</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span>
        <span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span>
        <span class="n">height_ratios</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
        <span class="n">is_smallest_xrange</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">h_pad</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="n">PRETTY_RENAMER</span><span class="p">[</span><span class="n">data_name</span><span class="p">],</span>
        <span class="n">n_samples</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">end</span><span class="o">=</span><span class="s2">&quot;</span><span class="se">\r</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>

</pre></div>
</div>
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>

</pre></div>
</div>
<img alt="_images/LNP_23_3.png" src="_images/LNP_23_3.png" />
<img alt="_images/LNP_23_4.png" src="_images/LNP_23_4.png" />
<img alt="_images/LNP_23_5.png" src="_images/LNP_23_5.png" />
</div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="LNPFs.html" title="previous page">Latent NPFs</a>
    <a class='right-next' id="next-link" href="AttnLNP.html" title="next page">Attentive Latent Neural Process (AttnLNP)</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yann Dubois<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="_static/js/index.js"></script>
    
  </body>
</html>